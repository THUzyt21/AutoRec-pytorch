{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e261d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6ddf9",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0c4bcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大用户ID:6040，最大Item ID:3952. 总记录数：1000209\n"
     ]
    }
   ],
   "source": [
    "max_user_id,max_item_it = 0,0\n",
    "records = []\n",
    "#训练集比例\n",
    "train_ratio = 0.9\n",
    "with open('ratings.dat',encoding='ISO-8859-1') as f:\n",
    "    for line in f:\n",
    "        tks = line.strip().split('::')\n",
    "        max_user_id = max(max_user_id,int(tks[0]))\n",
    "        max_item_it = max(max_item_it,int(tks[1]))\n",
    "        #以tuple的形式存储每一条评分记录\n",
    "        records.append((int(tks[0])-1,int(tks[1])-1,int(tks[2])))\n",
    "print(\"最大用户ID:{0}，最大Item ID:{1}. 总记录数：{2}\".format(max_user_id,max_item_it,len(records)))\n",
    "#打乱数据集顺序\n",
    "random.shuffle(records)\n",
    "#按一定比例划分测试集和训练集\n",
    "train_list = records[0:int(len(records)* train_ratio)]\n",
    "test_list = records[int(len(records)* train_ratio):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46838f4",
   "metadata": {},
   "source": [
    "## 把数据包装为torch数据集类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa95bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba333074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    #输入是rating list : [(user,item,rate),...]\n",
    "    def __init__(self,rating_list,n_user,n_item,user_based = True):\n",
    "        self.data = rating_list\n",
    "        self.user_based = user_based\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        #构建共现矩阵\n",
    "        self.x_mat = np.zeros((n_user, n_item))\n",
    "        #mask矩阵，有评分记为1否则为0\n",
    "        self.mask = np.zeros_like(self.x_mat)\n",
    "        #三元组列表存到矩阵中\n",
    "        for u,i,o in self.data:\n",
    "            self.x_mat[u][i] = o\n",
    "            self.mask[u][i] = 1\n",
    "        #转为torch.Tensor\n",
    "        self.x_mat = torch.from_numpy(self.x_mat).float() \n",
    "        self.mask = torch.from_numpy(self.mask).float() \n",
    "        #如果使用item-based协同过滤\n",
    "        if not user_based:\n",
    "            self.x_mat = self.x_mat.t()\n",
    "            self.mask = self.mask.t()\n",
    "    #重写getitem,len方法：\n",
    "        #作用：当实例对象P做P[key]运算时，会自动调用__getitem__方法\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_mat[idx],self.mask[idx]\n",
    "    def __len__(self):\n",
    "        if self.user_based: return self.n_user\n",
    "        return self.n_item\n",
    "    def get_matrix(self):\n",
    "        return self.x_mat, self.mask, self.user_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "71b92106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(train_list,max_user_id,max_item_it,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "36a37b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3952, 6040])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.get_matrix()[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "467cf0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41571ad8",
   "metadata": {},
   "source": [
    "## 构建AutoEncoder模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "52124ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,drop_out = 0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size), \n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size,input_size), \n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    #前向传播,此处将评分归一化\n",
    "    def forward(self,X):\n",
    "        X = (X-1)/4\n",
    "        X = self.decoder(self.encoder(X))\n",
    "        X = torch.clamp(X,0,1.0)\n",
    "        return X*4.0 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d6952a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#输入是max_used_id * max_item_id大小的Tensor\n",
    "net = AutoEncoder( max_user_id, 300)\n",
    "net.train()\n",
    "\n",
    "if(train_data.user_based):\n",
    "    feature_size = max_item_it\n",
    "else:\n",
    "    feature_size = max_user_id\n",
    "    \n",
    "def train(net, optim, train_loader, epoch):\n",
    "    features = torch.zeros(batch_size, feature_size)\n",
    "    masks = torch.zeros(batch_size, feature_size)\n",
    "    \n",
    "    for _, (feature, mask) in enumerate(train_loader):\n",
    "        #这里是为了利用batch_size不是128的数据\n",
    "        if mask.shape[0] == batch_size:\n",
    "            features.copy_(feature)\n",
    "            masks.copy_(mask)\n",
    "        else:\n",
    "            features = feature\n",
    "            masks = mask\n",
    "    #mask记录共现矩阵中哪里是1（即有评分的位置），用矩阵相乘可以加速计算\n",
    "    optim.zero_grad()\n",
    "    #AE恢复出的数据\n",
    "    output = net(features)\n",
    "    loss = F.mse_loss(output * masks, features * masks)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "def test(net,train_data,test_data):\n",
    "    #输入全量矩阵\n",
    "    x_mat = train_data.get_matrix()[0]\n",
    "    #输出恢复的矩阵\n",
    "    xc  = net(x_mat)\n",
    "    if not train_data.user_based:\n",
    "        xc = xc.t()\n",
    "    xc = xc.detach().numpy()\n",
    "    #用训练集恢复的数据看和测试集的差距\n",
    "    rmse = 0.0\n",
    "    for i,j,k in test_data:\n",
    "        rmse += (xc[i][j] - k)**2\n",
    "    rmse = np.sqrt(rmse/len(test_data))\n",
    "    print('rmse:', rmse.item())\n",
    "    \n",
    "def run(net, train_data,test_data, num_epoch, batch_size = batch_size):\n",
    "    #首先对net进行初始化，采用xavier_uniform\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    #优化器：带动量的SGD\n",
    "    optimizer = optim.SGD(net.parameters(), 0.2, momentum= 0.9, weight_decay= 1e-4)\n",
    "    print(\"模型初始化参数完毕，开始训练\")\n",
    "    for epoch in range(1, num_epoch + 1):\n",
    "        print('epoch: ' + str(epoch) + '/ ' +  str(num_epoch))\n",
    "        train_loader = data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "        train(net, optimizer, train_loader, epoch)\n",
    "        test(net,train_data, test_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6437b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型初始化参数完毕，开始训练\n",
      "epoch: 1/ 50\n",
      "rmse: 1.2692345392809132\n",
      "epoch: 2/ 50\n",
      "rmse: 1.2691351272014193\n",
      "epoch: 3/ 50\n",
      "rmse: 1.2690953027890337\n",
      "epoch: 4/ 50\n",
      "rmse: 1.2688918430179572\n",
      "epoch: 5/ 50\n",
      "rmse: 1.2685372216717046\n",
      "epoch: 6/ 50\n",
      "rmse: 1.268306313346322\n",
      "epoch: 7/ 50\n",
      "rmse: 1.2681253249475997\n",
      "epoch: 8/ 50\n",
      "rmse: 1.2677526955403762\n",
      "epoch: 9/ 50\n",
      "rmse: 1.2673948085114728\n",
      "epoch: 10/ 50\n",
      "rmse: 1.2671293250611437\n",
      "epoch: 11/ 50\n",
      "rmse: 1.2666144894085214\n",
      "epoch: 12/ 50\n",
      "rmse: 1.266371010036745\n",
      "epoch: 13/ 50\n",
      "rmse: 1.2655811019113627\n",
      "epoch: 14/ 50\n",
      "rmse: 1.2650658245782285\n",
      "epoch: 15/ 50\n",
      "rmse: 1.264842017368138\n",
      "epoch: 16/ 50\n",
      "rmse: 1.2641258012301526\n",
      "epoch: 17/ 50\n",
      "rmse: 1.2635871454219045\n",
      "epoch: 18/ 50\n",
      "rmse: 1.2633759129735416\n",
      "epoch: 19/ 50\n",
      "rmse: 1.2628902132123394\n",
      "epoch: 20/ 50\n",
      "rmse: 1.2623090766659821\n",
      "epoch: 21/ 50\n",
      "rmse: 1.261911394258746\n",
      "epoch: 22/ 50\n",
      "rmse: 1.2614363215996913\n",
      "epoch: 23/ 50\n",
      "rmse: 1.260931955739916\n",
      "epoch: 24/ 50\n",
      "rmse: 1.2602818556509503\n",
      "epoch: 25/ 50\n",
      "rmse: 1.2599431507353347\n",
      "epoch: 26/ 50\n",
      "rmse: 1.2593731494998026\n",
      "epoch: 27/ 50\n",
      "rmse: 1.2589706941228076\n",
      "epoch: 28/ 50\n",
      "rmse: 1.2587306417017685\n",
      "epoch: 29/ 50\n",
      "rmse: 1.2580333047682657\n",
      "epoch: 30/ 50\n",
      "rmse: 1.257956304474527\n",
      "epoch: 31/ 50\n",
      "rmse: 1.257162119241808\n",
      "epoch: 32/ 50\n",
      "rmse: 1.256536706478776\n",
      "epoch: 33/ 50\n",
      "rmse: 1.2560744134916848\n",
      "epoch: 34/ 50\n",
      "rmse: 1.2559907176957026\n",
      "epoch: 35/ 50\n",
      "rmse: 1.2556339826321947\n",
      "epoch: 36/ 50\n",
      "rmse: 1.2548343735894616\n",
      "epoch: 37/ 50\n",
      "rmse: 1.2547288828967886\n",
      "epoch: 38/ 50\n",
      "rmse: 1.2539551697575326\n",
      "epoch: 39/ 50\n",
      "rmse: 1.253576504323852\n",
      "epoch: 40/ 50\n",
      "rmse: 1.2530672866643535\n",
      "epoch: 41/ 50\n",
      "rmse: 1.2528717727467642\n",
      "epoch: 42/ 50\n",
      "rmse: 1.2521597498568153\n",
      "epoch: 43/ 50\n",
      "rmse: 1.252333654607575\n",
      "epoch: 44/ 50\n",
      "rmse: 1.2516895323861166\n",
      "epoch: 45/ 50\n",
      "rmse: 1.2511258615637415\n",
      "epoch: 46/ 50\n",
      "rmse: 1.2508353149235938\n",
      "epoch: 47/ 50\n",
      "rmse: 1.2504161148350275\n",
      "epoch: 48/ 50\n",
      "rmse: 1.2498706935766688\n",
      "epoch: 49/ 50\n",
      "rmse: 1.2497703023743538\n",
      "epoch: 50/ 50\n",
      "rmse: 1.2494603756404314\n"
     ]
    }
   ],
   "source": [
    "run(net,train_data=j,test_data=test_list,num_epoch=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
